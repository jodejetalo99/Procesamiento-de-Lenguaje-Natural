{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### José de Jesús Tapia López\n",
    "### Procesamiento de Lenguaje Natural\n",
    "### 06 de Octubre del 2020\n",
    "### Tema 3 - Actividad Sumativa 1 \n",
    "\n",
    "\n",
    "Escribe un programa en Python que lea cada uno de estos textos, tokenice, y cuente el número de tokens y types de cada uno de ellos (sin usar ninguna librería).\n",
    "\n",
    "- LA ÚLTIMA INOCENCIA, Alejandra Pizarnik\n",
    "\n",
    "- Fragmento del poema XXVI de Dulce María Loynaz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para tokenizar, calcular el número de tokens y types, recibe como parámetro una cadena\n",
    "def tokenizar(string): \n",
    "    \n",
    "    # eliminamos signos de puntuación\n",
    "    signos_puntuacion = ('!','.',':',',',';','*','?','¿','¡','*','-','(',')','[',']','\\'','\"','>','<')\n",
    "    \n",
    "    palabras = \"\".join(c for c in string if c not in signos_puntuacion)\n",
    "    \n",
    "    # Pasamos todo a minúscula\n",
    "    palabras = palabras.lower()\n",
    "    print(\"Texto pre-procesado: \", palabras,'\\n')\n",
    "  \n",
    "    # convierte todo el string en una lista de palabras\n",
    "    \n",
    "    tokens = palabras.split() \n",
    "    \n",
    "    # obtenemos las palabras distintas que hay en el string\n",
    "    palabras_distintas = set(tokens)\n",
    "    \n",
    "    # NOTA: si no hubieramos eliminado los signos de puntuación, en la split\n",
    "    # anterior podría ocurrir que, si el string fuera algo así: 'hola , te quiero',\n",
    "    # la lista anterior consideraría a la ',' como un elemento de ella \n",
    "    # (al momento de hacer el split)\n",
    "    \n",
    "    numero_tokens = len(tokens)\n",
    "    types = list(palabras_distintas)\n",
    "    numero_types = len(palabras_distintas)\n",
    "    \n",
    "    print(\"Tokenización: \", tokens,'\\n')\n",
    "    print(\"Total de tokens: \", numero_tokens,'\\n')\n",
    "    print(\"Types: \", types,'\\n')\n",
    "    print(\"Total de types: \", numero_types,'\\n')\n",
    "    \n",
    "    # el return lo comento porque tal vez ahorita no sirva de mucho,\n",
    "    # pero podría servir en futuras tareas\n",
    "    \n",
    "    #return [tokens, types]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ultimaInocencia.txt', 'r') as archivo:\n",
    "    ultima_inocencia = archivo.read().replace('\\n', ' ')\n",
    "with open('DulceMaríaLoynaz.txt', 'r') as archivo2:\n",
    "    poema_dml = archivo2.read().replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto pre-procesado:  partir en cuerpo y alma partir partir deshacerse de las miradas piedras opresoras que duermen en la garganta  he de partir no más inercia bajo el sol no más sangre anonadada no más fila para morir  he de partir  pero arremete viajera \n",
      "\n",
      "Tokenización:  ['partir', 'en', 'cuerpo', 'y', 'alma', 'partir', 'partir', 'deshacerse', 'de', 'las', 'miradas', 'piedras', 'opresoras', 'que', 'duermen', 'en', 'la', 'garganta', 'he', 'de', 'partir', 'no', 'más', 'inercia', 'bajo', 'el', 'sol', 'no', 'más', 'sangre', 'anonadada', 'no', 'más', 'fila', 'para', 'morir', 'he', 'de', 'partir', 'pero', 'arremete', 'viajera'] \n",
      "\n",
      "Total de tokens:  42 \n",
      "\n",
      "Types:  ['la', 'pero', 'partir', 'garganta', 'sangre', 'para', 'y', 'fila', 'sol', 'en', 'bajo', 'anonadada', 'duermen', 'no', 'cuerpo', 'he', 'que', 'morir', 'deshacerse', 'alma', 'viajera', 'el', 'inercia', 'las', 'piedras', 'de', 'arremete', 'opresoras', 'miradas', 'más'] \n",
      "\n",
      "Total de types:  30 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizar(ultima_inocencia) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto pre-procesado:  he de amoldarme a ti como el río a su cauce como el mar a su playa como la espada a su vaina he de correr en ti he de cantar en ti he de guardarme en ti ya para siempre fuera de ti ha de sobrarme el mundo como le sobra al río el aire al mar la tierra a la espada la mesa del convite dentro de ti no ha de faltarme blandura de limo para mi corriente perfil de viento para mis olas ceñidura y reposo para mi acero \n",
      "\n",
      "Tokenización:  ['he', 'de', 'amoldarme', 'a', 'ti', 'como', 'el', 'río', 'a', 'su', 'cauce', 'como', 'el', 'mar', 'a', 'su', 'playa', 'como', 'la', 'espada', 'a', 'su', 'vaina', 'he', 'de', 'correr', 'en', 'ti', 'he', 'de', 'cantar', 'en', 'ti', 'he', 'de', 'guardarme', 'en', 'ti', 'ya', 'para', 'siempre', 'fuera', 'de', 'ti', 'ha', 'de', 'sobrarme', 'el', 'mundo', 'como', 'le', 'sobra', 'al', 'río', 'el', 'aire', 'al', 'mar', 'la', 'tierra', 'a', 'la', 'espada', 'la', 'mesa', 'del', 'convite', 'dentro', 'de', 'ti', 'no', 'ha', 'de', 'faltarme', 'blandura', 'de', 'limo', 'para', 'mi', 'corriente', 'perfil', 'de', 'viento', 'para', 'mis', 'olas', 'ceñidura', 'y', 'reposo', 'para', 'mi', 'acero'] \n",
      "\n",
      "Total de tokens:  92 \n",
      "\n",
      "Types:  ['a', 'aire', 'la', 'espada', 'corriente', 'fuera', 'acero', 'para', 'mar', 'blandura', 'y', 'mi', 'ceñidura', 'reposo', 'en', 'sobra', 'convite', 'tierra', 'como', 'no', 'cantar', 'he', 'playa', 'viento', 'mis', 'ti', 'ya', 'ha', 'guardarme', 'le', 'olas', 'sobrarme', 'el', 'perfil', 'limo', 'amoldarme', 'mundo', 'del', 'vaina', 'siempre', 'dentro', 'cauce', 'correr', 'río', 'mesa', 'su', 'al', 'de', 'faltarme'] \n",
      "\n",
      "Total de types:  49 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizar(poema_dml) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
